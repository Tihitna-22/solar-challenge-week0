{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exploratory Data Analysis (EDA) - [COUNTRY]\n",
        "\n",
        "## Objective\n",
        "Profile, clean, and explore the solar dataset to prepare it for comparison and region-ranking tasks.\n",
        "\n",
        "## Instructions\n",
        "1. Replace `[COUNTRY]` with your country name (e.g., Benin)\n",
        "2. Update the data file path in the data loading section\n",
        "3. Run all cells sequentially\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Libraries and Load Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style for better-looking plots\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "# Configuration\n",
        "COUNTRY = \"[COUNTRY]\"  # Replace with your country name\n",
        "DATA_PATH = \"../data/[country]_raw.csv\"  # Update with your data file path\n",
        "OUTPUT_PATH = f\"../data/{COUNTRY.lower()}_clean.csv\"\n",
        "\n",
        "print(f\"Loading data for {COUNTRY}...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "\n",
        "# Display basic information\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"\\nColumn names:\\n{df.columns.tolist()}\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert Timestamp to datetime if it's not already\n",
        "if 'Timestamp' in df.columns:\n",
        "    df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
        "    df = df.sort_values('Timestamp').reset_index(drop=True)\n",
        "\n",
        "df.info()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Summary Statistics & Missing Value Report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary statistics for all numeric columns\n",
        "print(\"=\" * 80)\n",
        "print(\"SUMMARY STATISTICS\")\n",
        "print(\"=\" * 80)\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "print(f\"\\nNumeric columns: {len(numeric_cols)}\")\n",
        "df[numeric_cols].describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Missing value analysis\n",
        "print(\"=\" * 80)\n",
        "print(\"MISSING VALUE REPORT\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "missing_data = df.isna().sum()\n",
        "missing_percent = (missing_data / len(df)) * 100\n",
        "\n",
        "missing_df = pd.DataFrame({\n",
        "    'Column': missing_data.index,\n",
        "    'Missing Count': missing_data.values,\n",
        "    'Missing Percentage': missing_percent.values\n",
        "})\n",
        "missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Percentage', ascending=False)\n",
        "\n",
        "print(f\"\\nTotal missing values: {missing_data.sum()}\")\n",
        "print(f\"\\nColumns with missing values:\")\n",
        "print(missing_df.to_string(index=False))\n",
        "\n",
        "# Flag columns with >5% nulls\n",
        "high_missing = missing_df[missing_df['Missing Percentage'] > 5]\n",
        "if len(high_missing) > 0:\n",
        "    print(f\"\\n⚠️  WARNING: Columns with >5% missing values:\")\n",
        "    print(high_missing[['Column', 'Missing Percentage']].to_string(index=False))\n",
        "else:\n",
        "    print(\"\\n✅ No columns with >5% missing values\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize missing values\n",
        "if len(missing_df) > 0:\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    missing_df_sorted = missing_df.sort_values('Missing Percentage', ascending=True)\n",
        "    plt.barh(missing_df_sorted['Column'], missing_df_sorted['Missing Percentage'])\n",
        "    plt.axvline(x=5, color='r', linestyle='--', label='5% threshold')\n",
        "    plt.xlabel('Missing Percentage (%)')\n",
        "    plt.ylabel('Columns')\n",
        "    plt.title(f'Missing Values by Column - {COUNTRY}')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Outlier Detection & Basic Cleaning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Key columns for outlier detection\n",
        "key_columns = ['GHI', 'DNI', 'DHI', 'ModA', 'ModB', 'WS', 'WSgust']\n",
        "\n",
        "# Check which columns exist in the dataset\n",
        "available_key_cols = [col for col in key_columns if col in df.columns]\n",
        "print(f\"Columns available for outlier detection: {available_key_cols}\")\n",
        "\n",
        "# Compute Z-scores for key columns\n",
        "z_scores = pd.DataFrame()\n",
        "outlier_flags = pd.DataFrame()\n",
        "\n",
        "for col in available_key_cols:\n",
        "    if col in numeric_cols:\n",
        "        z_scores[col] = np.abs(stats.zscore(df[col].dropna()))\n",
        "        outlier_flags[col] = z_scores[col] > 3\n",
        "\n",
        "print(f\"\\nOutlier detection using Z-score (|Z| > 3):\")\n",
        "print(\"-\" * 80)\n",
        "for col in available_key_cols:\n",
        "    if col in outlier_flags.columns:\n",
        "        outlier_count = outlier_flags[col].sum()\n",
        "        outlier_pct = (outlier_count / len(df)) * 100\n",
        "        print(f\"{col}: {outlier_count} outliers ({outlier_pct:.2f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize outliers using box plots\n",
        "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, col in enumerate(available_key_cols[:8]):  # Plot up to 8 columns\n",
        "    if col in df.columns:\n",
        "        df.boxplot(column=col, ax=axes[idx])\n",
        "        axes[idx].set_title(f'{col} - Outliers')\n",
        "        axes[idx].grid(True, alpha=0.3)\n",
        "\n",
        "# Hide unused subplots\n",
        "for idx in range(len(available_key_cols), 8):\n",
        "    axes[idx].set_visible(False)\n",
        "\n",
        "plt.suptitle(f'Outlier Detection - Box Plots for Key Variables - {COUNTRY}', fontsize=16, y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a copy for cleaning\n",
        "df_clean = df.copy()\n",
        "\n",
        "# Handle missing values in key columns (impute with median)\n",
        "key_columns_for_imputation = ['GHI', 'DNI', 'DHI', 'Tamb', 'RH', 'WS', 'ModA', 'ModB']\n",
        "available_impute_cols = [col for col in key_columns_for_imputation if col in df_clean.columns]\n",
        "\n",
        "print(\"Handling missing values:\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "for col in available_impute_cols:\n",
        "    if col in numeric_cols:\n",
        "        missing_before = df_clean[col].isna().sum()\n",
        "        if missing_before > 0:\n",
        "            median_val = df_clean[col].median()\n",
        "            df_clean[col].fillna(median_val, inplace=True)\n",
        "            print(f\"{col}: Imputed {missing_before} missing values with median ({median_val:.2f})\")\n",
        "\n",
        "print(f\"\\nMissing values after imputation: {df_clean.isna().sum().sum()}\")\n",
        "\n",
        "# Cap outliers at 3 standard deviations for key columns\n",
        "critical_cols = ['GHI', 'DNI', 'DHI', 'ModA', 'ModB', 'WS', 'WSgust']\n",
        "for col in critical_cols:\n",
        "    if col in df_clean.columns and col in numeric_cols:\n",
        "        mean_val = df_clean[col].mean()\n",
        "        std_val = df_clean[col].std()\n",
        "        df_clean[col] = df_clean[col].clip(lower=mean_val - 3*std_val, upper=mean_val + 3*std_val)\n",
        "\n",
        "print(f\"\\nOutliers capped at ±3 standard deviations\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Time Series Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper function to get units\n",
        "def get_units(var):\n",
        "    \"\"\"Helper function to get units for variables\"\"\"\n",
        "    units = {\n",
        "        'GHI': 'W/m²', 'DNI': 'W/m²', 'DHI': 'W/m²',\n",
        "        'ModA': 'W/m²', 'ModB': 'W/m²',\n",
        "        'Tamb': '°C', 'TModA': '°C', 'TModB': '°C',\n",
        "        'RH': '%', 'WS': 'm/s', 'WSgust': 'm/s',\n",
        "        'BP': 'hPa', 'Precipitation': 'mm/min'\n",
        "    }\n",
        "    return units.get(var, '')\n",
        "\n",
        "# Ensure Timestamp is the index for time series analysis\n",
        "if 'Timestamp' in df_clean.columns:\n",
        "    df_clean['Date'] = df_clean['Timestamp'].dt.date\n",
        "    df_clean['Month'] = df_clean['Timestamp'].dt.month\n",
        "    df_clean['Hour'] = df_clean['Timestamp'].dt.hour\n",
        "    df_clean['DayOfYear'] = df_clean['Timestamp'].dt.dayofyear\n",
        "\n",
        "# Time series plots for key variables\n",
        "ts_vars = ['GHI', 'DNI', 'DHI', 'Tamb']\n",
        "available_ts_vars = [col for col in ts_vars if col in df_clean.columns]\n",
        "\n",
        "fig, axes = plt.subplots(len(available_ts_vars), 1, figsize=(16, 4*len(available_ts_vars)))\n",
        "if len(available_ts_vars) == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "for idx, var in enumerate(available_ts_vars):\n",
        "    if 'Timestamp' in df_clean.columns:\n",
        "        axes[idx].plot(df_clean['Timestamp'], df_clean[var], alpha=0.6, linewidth=0.5)\n",
        "        axes[idx].set_title(f'{var} Over Time - {COUNTRY}', fontsize=14)\n",
        "        axes[idx].set_xlabel('Timestamp')\n",
        "        axes[idx].set_ylabel(f'{var} ({get_units(var)})')\n",
        "        axes[idx].grid(True, alpha=0.3)\n",
        "        plt.setp(axes[idx].xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Monthly patterns\n",
        "if 'Month' in df_clean.columns and 'GHI' in df_clean.columns:\n",
        "    monthly_avg = df_clean.groupby('Month')[available_ts_vars].mean()\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
        "                   'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
        "    \n",
        "    for idx, var in enumerate(available_ts_vars[:4]):\n",
        "        axes[idx].bar(range(1, 13), monthly_avg[var], color='steelblue', alpha=0.7)\n",
        "        axes[idx].set_title(f'Average {var} by Month - {COUNTRY}', fontsize=12)\n",
        "        axes[idx].set_xlabel('Month')\n",
        "        axes[idx].set_ylabel(f'{var} ({get_units(var)})')\n",
        "        axes[idx].set_xticks(range(1, 13))\n",
        "        axes[idx].set_xticklabels(month_names, rotation=45)\n",
        "        axes[idx].grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hourly patterns (diurnal cycle)\n",
        "if 'Hour' in df_clean.columns and 'GHI' in df_clean.columns:\n",
        "    hourly_avg = df_clean.groupby('Hour')[available_ts_vars].mean()\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(14, 6))\n",
        "    for var in available_ts_vars:\n",
        "        ax.plot(hourly_avg.index, hourly_avg[var], marker='o', label=var, linewidth=2)\n",
        "    \n",
        "    ax.set_title(f'Average Diurnal Cycle (Hourly Patterns) - {COUNTRY}', fontsize=14)\n",
        "    ax.set_xlabel('Hour of Day')\n",
        "    ax.set_ylabel('Average Value')\n",
        "    ax.set_xticks(range(0, 24, 2))\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Cleaning Impact Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze impact of cleaning events on ModA and ModB\n",
        "if 'Cleaning' in df_clean.columns:\n",
        "    cleaning_analysis = df_clean.groupby('Cleaning')[['ModA', 'ModB']].mean()\n",
        "    \n",
        "    print(\"Cleaning Impact Analysis:\")\n",
        "    print(\"=\" * 80)\n",
        "    print(cleaning_analysis)\n",
        "    \n",
        "    # Visualize cleaning impact\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    \n",
        "    for idx, mod in enumerate(['ModA', 'ModB']):\n",
        "        if mod in df_clean.columns:\n",
        "            cleaning_analysis[mod].plot(kind='bar', ax=axes[idx], color=['lightcoral', 'lightgreen'])\n",
        "            axes[idx].set_title(f'Average {mod} by Cleaning Status - {COUNTRY}')\n",
        "            axes[idx].set_xlabel('Cleaning (0=No, 1=Yes)')\n",
        "            axes[idx].set_ylabel(f'{mod} (W/m²)')\n",
        "            axes[idx].set_xticklabels(['No Cleaning', 'Cleaning'], rotation=0)\n",
        "            axes[idx].grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Before/After cleaning comparison\n",
        "    if len(df_clean[df_clean['Cleaning'] == 1]) > 0:\n",
        "        print(\"\\nDetailed Cleaning Analysis:\")\n",
        "        print(\"-\" * 80)\n",
        "        for mod in ['ModA', 'ModB']:\n",
        "            if mod in df_clean.columns:\n",
        "                before = df_clean[df_clean['Cleaning'] == 0][mod].mean()\n",
        "                after = df_clean[df_clean['Cleaning'] == 1][mod].mean()\n",
        "                improvement = ((after - before) / before) * 100\n",
        "                print(f\"{mod}: Before={before:.2f}, After={after:.2f}, Improvement={improvement:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Correlation & Relationship Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation analysis\n",
        "corr_vars = ['GHI', 'DNI', 'DHI', 'TModA', 'TModB', 'Tamb', 'RH', 'WS', 'WSgust', 'BP']\n",
        "available_corr_vars = [col for col in corr_vars if col in df_clean.columns and col in numeric_cols]\n",
        "\n",
        "if len(available_corr_vars) > 0:\n",
        "    corr_matrix = df_clean[available_corr_vars].corr()\n",
        "    \n",
        "    plt.figure(figsize=(14, 12))\n",
        "    sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
        "                square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
        "    plt.title(f'Correlation Heatmap - {COUNTRY}', fontsize=16, pad=20)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Print strongest correlations\n",
        "    print(\"\\nStrongest Correlations (|r| > 0.7):\")\n",
        "    print(\"-\" * 80)\n",
        "    for i in range(len(corr_matrix.columns)):\n",
        "        for j in range(i+1, len(corr_matrix.columns)):\n",
        "            corr_val = corr_matrix.iloc[i, j]\n",
        "            if abs(corr_val) > 0.7:\n",
        "                print(f\"{corr_matrix.columns[i]} vs {corr_matrix.columns[j]}: {corr_val:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scatter plots: WS, WSgust, WD vs. GHI\n",
        "if 'GHI' in df_clean.columns:\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "    \n",
        "    scatter_vars = [('WS', 'Wind Speed'), ('WSgust', 'Wind Gust Speed'), ('WD', 'Wind Direction')]\n",
        "    \n",
        "    for idx, (var, label) in enumerate(scatter_vars):\n",
        "        if var in df_clean.columns:\n",
        "            axes[idx].scatter(df_clean[var], df_clean['GHI'], alpha=0.3, s=10)\n",
        "            axes[idx].set_xlabel(f'{label} ({get_units(var)})')\n",
        "            axes[idx].set_ylabel(f'GHI (W/m²)')\n",
        "            axes[idx].set_title(f'GHI vs {label} - {COUNTRY}')\n",
        "            axes[idx].grid(True, alpha=0.3)\n",
        "            \n",
        "            # Add correlation coefficient\n",
        "            corr_coef = df_clean[[var, 'GHI']].corr().iloc[0, 1]\n",
        "            axes[idx].text(0.05, 0.95, f'r = {corr_coef:.3f}', \n",
        "                          transform=axes[idx].transAxes, \n",
        "                          verticalalignment='top',\n",
        "                          bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scatter plots: RH vs. Tamb and RH vs. GHI\n",
        "if 'RH' in df_clean.columns:\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    \n",
        "    # RH vs Tamb\n",
        "    if 'Tamb' in df_clean.columns:\n",
        "        axes[0].scatter(df_clean['RH'], df_clean['Tamb'], alpha=0.3, s=10, color='blue')\n",
        "        axes[0].set_xlabel('Relative Humidity (%)')\n",
        "        axes[0].set_ylabel('Ambient Temperature (°C)')\n",
        "        axes[0].set_title(f'RH vs Tamb - {COUNTRY}')\n",
        "        axes[0].grid(True, alpha=0.3)\n",
        "        corr_rh_tamb = df_clean[['RH', 'Tamb']].corr().iloc[0, 1]\n",
        "        axes[0].text(0.05, 0.95, f'r = {corr_rh_tamb:.3f}', \n",
        "                    transform=axes[0].transAxes, \n",
        "                    verticalalignment='top',\n",
        "                    bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "    \n",
        "    # RH vs GHI\n",
        "    if 'GHI' in df_clean.columns:\n",
        "        axes[1].scatter(df_clean['RH'], df_clean['GHI'], alpha=0.3, s=10, color='orange')\n",
        "        axes[1].set_xlabel('Relative Humidity (%)')\n",
        "        axes[1].set_ylabel('GHI (W/m²)')\n",
        "        axes[1].set_title(f'RH vs GHI - {COUNTRY}')\n",
        "        axes[1].grid(True, alpha=0.3)\n",
        "        corr_rh_ghi = df_clean[['RH', 'GHI']].corr().iloc[0, 1]\n",
        "        axes[1].text(0.05, 0.95, f'r = {corr_rh_ghi:.3f}', \n",
        "                    transform=axes[1].transAxes, \n",
        "                    verticalalignment='top',\n",
        "                    bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Wind & Distribution Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Wind Rose (Radial Bar Plot)\n",
        "if 'WD' in df_clean.columns and 'WS' in df_clean.columns:\n",
        "    # Create wind direction bins (16 directions)\n",
        "    df_clean['WD_bin'] = pd.cut(df_clean['WD'], bins=16, labels=range(16))\n",
        "    \n",
        "    # Calculate average wind speed by direction\n",
        "    wind_rose = df_clean.groupby('WD_bin')['WS'].mean()\n",
        "    \n",
        "    # Create radial plot\n",
        "    fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))\n",
        "    \n",
        "    # Convert bin numbers to angles (in radians)\n",
        "    angles = np.linspace(0, 2*np.pi, 16, endpoint=False)\n",
        "    \n",
        "    # Plot bars\n",
        "    bars = ax.bar(angles, wind_rose.values, width=2*np.pi/16, color='steelblue', alpha=0.7)\n",
        "    \n",
        "    # Set direction labels\n",
        "    direction_labels = ['N', 'NNE', 'NE', 'ENE', 'E', 'ESE', 'SE', 'SSE',\n",
        "                       'S', 'SSW', 'SW', 'WSW', 'W', 'WNW', 'NW', 'NNW']\n",
        "    ax.set_xticks(angles)\n",
        "    ax.set_xticklabels(direction_labels)\n",
        "    \n",
        "    ax.set_title(f'Wind Rose - Average Wind Speed by Direction - {COUNTRY}', \n",
        "                fontsize=14, pad=20)\n",
        "    ax.set_ylabel('Wind Speed (m/s)', labelpad=30)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Histograms for GHI and WS\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# GHI Histogram\n",
        "if 'GHI' in df_clean.columns:\n",
        "    axes[0].hist(df_clean['GHI'].dropna(), bins=50, color='steelblue', alpha=0.7, edgecolor='black')\n",
        "    axes[0].set_xlabel('GHI (W/m²)')\n",
        "    axes[0].set_ylabel('Frequency')\n",
        "    axes[0].set_title(f'Distribution of GHI - {COUNTRY}')\n",
        "    axes[0].grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    # Add statistics\n",
        "    mean_ghi = df_clean['GHI'].mean()\n",
        "    median_ghi = df_clean['GHI'].median()\n",
        "    axes[0].axvline(mean_ghi, color='red', linestyle='--', label=f'Mean: {mean_ghi:.1f}')\n",
        "    axes[0].axvline(median_ghi, color='green', linestyle='--', label=f'Median: {median_ghi:.1f}')\n",
        "    axes[0].legend()\n",
        "\n",
        "# WS Histogram\n",
        "if 'WS' in df_clean.columns:\n",
        "    axes[1].hist(df_clean['WS'].dropna(), bins=50, color='orange', alpha=0.7, edgecolor='black')\n",
        "    axes[1].set_xlabel('Wind Speed (m/s)')\n",
        "    axes[1].set_ylabel('Frequency')\n",
        "    axes[1].set_title(f'Distribution of Wind Speed - {COUNTRY}')\n",
        "    axes[1].grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    # Add statistics\n",
        "    mean_ws = df_clean['WS'].mean()\n",
        "    median_ws = df_clean['WS'].median()\n",
        "    axes[1].axvline(mean_ws, color='red', linestyle='--', label=f'Mean: {mean_ws:.2f}')\n",
        "    axes[1].axvline(median_ws, color='green', linestyle='--', label=f'Median: {median_ws:.2f}')\n",
        "    axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Temperature Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Temperature and RH relationship analysis\n",
        "if 'Tamb' in df_clean.columns and 'RH' in df_clean.columns:\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    \n",
        "    # 1. RH vs Tamb scatter with density\n",
        "    axes[0, 0].hexbin(df_clean['RH'], df_clean['Tamb'], gridsize=30, cmap='YlOrRd')\n",
        "    axes[0, 0].set_xlabel('Relative Humidity (%)')\n",
        "    axes[0, 0].set_ylabel('Ambient Temperature (°C)')\n",
        "    axes[0, 0].set_title(f'RH vs Tamb (Density) - {COUNTRY}')\n",
        "    plt.colorbar(axes[0, 0].collections[0], ax=axes[0, 0])\n",
        "    \n",
        "    # 2. RH vs GHI\n",
        "    if 'GHI' in df_clean.columns:\n",
        "        axes[0, 1].hexbin(df_clean['RH'], df_clean['GHI'], gridsize=30, cmap='Blues')\n",
        "        axes[0, 1].set_xlabel('Relative Humidity (%)')\n",
        "        axes[0, 1].set_ylabel('GHI (W/m²)')\n",
        "        axes[0, 1].set_title(f'RH vs GHI (Density) - {COUNTRY}')\n",
        "        plt.colorbar(axes[0, 1].collections[0], ax=axes[0, 1])\n",
        "    \n",
        "    # 3. Temperature distribution by RH levels\n",
        "    df_clean['RH_category'] = pd.cut(df_clean['RH'], bins=[0, 30, 60, 100], \n",
        "                                     labels=['Low (0-30%)', 'Medium (30-60%)', 'High (60-100%)'])\n",
        "    if 'RH_category' in df_clean.columns:\n",
        "        df_clean.boxplot(column='Tamb', by='RH_category', ax=axes[1, 0])\n",
        "        axes[1, 0].set_title(f'Tamb Distribution by RH Category - {COUNTRY}')\n",
        "        axes[1, 0].set_xlabel('RH Category')\n",
        "        axes[1, 0].set_ylabel('Ambient Temperature (°C)')\n",
        "    \n",
        "    # 4. GHI distribution by RH levels\n",
        "    if 'GHI' in df_clean.columns and 'RH_category' in df_clean.columns:\n",
        "        df_clean.boxplot(column='GHI', by='RH_category', ax=axes[1, 1])\n",
        "        axes[1, 1].set_title(f'GHI Distribution by RH Category - {COUNTRY}')\n",
        "        axes[1, 1].set_xlabel('RH Category')\n",
        "        axes[1, 1].set_ylabel('GHI (W/m²)')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Statistical summary\n",
        "    print(\"Temperature and RH Relationship:\")\n",
        "    print(\"=\" * 80)\n",
        "    if 'RH_category' in df_clean.columns:\n",
        "        summary = df_clean.groupby('RH_category')[['Tamb', 'GHI']].agg(['mean', 'std'])\n",
        "        print(summary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Bubble Chart\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bubble Chart: GHI vs. Tamb with bubble size = RH or BP\n",
        "if 'GHI' in df_clean.columns and 'Tamb' in df_clean.columns:\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "    \n",
        "    # Sample data for better visualization (if dataset is too large)\n",
        "    sample_size = min(5000, len(df_clean))\n",
        "    df_sample = df_clean.sample(n=sample_size, random_state=42)\n",
        "    \n",
        "    # Bubble chart with RH as bubble size\n",
        "    if 'RH' in df_clean.columns:\n",
        "        scatter1 = axes[0].scatter(df_sample['Tamb'], df_sample['GHI'], \n",
        "                                  s=df_sample['RH']*5, alpha=0.5, \n",
        "                                  c=df_sample['RH'], cmap='viridis')\n",
        "        axes[0].set_xlabel('Ambient Temperature (°C)')\n",
        "        axes[0].set_ylabel('GHI (W/m²)')\n",
        "        axes[0].set_title(f'GHI vs Tamb (Bubble Size = RH) - {COUNTRY}')\n",
        "        axes[0].grid(True, alpha=0.3)\n",
        "        plt.colorbar(scatter1, ax=axes[0], label='RH (%)')\n",
        "    \n",
        "    # Bubble chart with BP as bubble size\n",
        "    if 'BP' in df_clean.columns:\n",
        "        # Normalize BP for bubble size (scale to reasonable range)\n",
        "        bp_normalized = (df_sample['BP'] - df_sample['BP'].min()) / (df_sample['BP'].max() - df_sample['BP'].min()) * 200 + 10\n",
        "        scatter2 = axes[1].scatter(df_sample['Tamb'], df_sample['GHI'], \n",
        "                                  s=bp_normalized, alpha=0.5, \n",
        "                                  c=df_sample['BP'], cmap='plasma')\n",
        "        axes[1].set_xlabel('Ambient Temperature (°C)')\n",
        "        axes[1].set_ylabel('GHI (W/m²)')\n",
        "        axes[1].set_title(f'GHI vs Tamb (Bubble Size = BP) - {COUNTRY}')\n",
        "        axes[1].grid(True, alpha=0.3)\n",
        "        plt.colorbar(scatter2, ax=axes[1], label='BP (hPa)')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Summary & Export Cleaned Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final summary\n",
        "print(\"=\" * 80)\n",
        "print(f\"EDA SUMMARY FOR {COUNTRY}\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\nOriginal dataset shape: {df.shape}\")\n",
        "print(f\"Cleaned dataset shape: {df_clean.shape}\")\n",
        "print(f\"Rows removed: {df.shape[0] - df_clean.shape[0]}\")\n",
        "print(f\"Columns: {df_clean.shape[1]}\")\n",
        "\n",
        "print(f\"\\nMissing values:\")\n",
        "print(f\"  Before cleaning: {df.isna().sum().sum()}\")\n",
        "print(f\"  After cleaning: {df_clean.isna().sum().sum()}\")\n",
        "\n",
        "if 'GHI' in df_clean.columns:\n",
        "    print(f\"\\nKey Statistics (GHI):\")\n",
        "    print(f\"  Mean: {df_clean['GHI'].mean():.2f} W/m²\")\n",
        "    print(f\"  Median: {df_clean['GHI'].median():.2f} W/m²\")\n",
        "    print(f\"  Std: {df_clean['GHI'].std():.2f} W/m²\")\n",
        "    print(f\"  Min: {df_clean['GHI'].min():.2f} W/m²\")\n",
        "    print(f\"  Max: {df_clean['GHI'].max():.2f} W/m²\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove temporary columns before exporting\n",
        "cols_to_drop = ['Date', 'Month', 'Hour', 'DayOfYear', 'WD_bin', 'RH_category']\n",
        "export_cols = [col for col in cols_to_drop if col in df_clean.columns]\n",
        "df_export = df_clean.drop(columns=export_cols, errors='ignore')\n",
        "\n",
        "# Export cleaned data\n",
        "import os\n",
        "os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)\n",
        "df_export.to_csv(OUTPUT_PATH, index=False)\n",
        "print(f\"\\n✅ Cleaned data exported to: {OUTPUT_PATH}\")\n",
        "print(f\"   File size: {os.path.getsize(OUTPUT_PATH) / 1024 / 1024:.2f} MB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References & Insights\n",
        "\n",
        "### Key Insights:\n",
        "1. **Data Quality**: [Add your observations about data quality]\n",
        "2. **Solar Patterns**: [Add insights about solar radiation patterns]\n",
        "3. **Weather Impact**: [Add insights about weather variables]\n",
        "4. **Cleaning Impact**: [Add insights about cleaning events]\n",
        "\n",
        "### Statistical Distributions Observed:\n",
        "- [Add observations about distributions]\n",
        "\n",
        "### Actionable Insights:\n",
        "- [Add actionable insights gained from EDA]\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
